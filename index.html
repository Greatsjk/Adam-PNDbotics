<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>UniBind</title>
    <meta name="author" content="Yuanhuiyi Lyu, Xu Zheng">
    <meta name="description" content="Project page of UniBind">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Whole-body Humanoid Robot Locomotion with Human Reference<br /> 
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                           Qiang Zhang*
                        </a>
                        
                        <br /> MICS Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp

                    </li>

                    <li>
                        Cui Petter*
                      </a>
                      <br /> PNDbotics
                      <br /> &nbsp &nbsp
                    </li>
                <li>
                                 David Yan
                                </a>
                                <br /> PNDbotics
                                <br /> &nbsp &nbsp
                            </li>

                            <li>

                           Jingkai Sun
                        </a>
                        <br /> MICS Thrust, HKUST(GZ) 
			<br /> &nbsp &nbsp 
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                           Yiqun Duan
                        </a>
                        
                        <br /> AI Centre, UTS
                        <br /> &nbsp &nbsp

                    </li>

                    <li>
                        Arthur Zhang
                      </a>
                      <br /> PNDbotics
                      <br /> &nbsp &nbsp
                    </li>
                <li>
                                 Renjing Xu
                                </a>
                                <br /> MICS Thrust, HKUST(GZ)
                                <br /> &nbsp &nbsp
        	</li>
                </ul>
            </div>
        </div>


        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			    <a href="https://arxiv.org/pdf/2402.18294.pdf">
                            <img src="./images/arxiv.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
			     <a href="https://www.youtube.com/watch?v=7hK2ySYBa1I">
                            <img src="./images/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Youtube</strong></h4>
                            </a>
                        </li>
                        <li> 
                            <a href="https://www.bilibili.com/video/BV1KZ421a7gP/?spm_id_from=333.337.search-card.all.click&vd_source=dfb078abd1e90d78a5f2d515734e9d86">
                            <img src="./images/bilibili_icon.jpg" height="100px"><br>
                                <h4><strong>Bilibili</strong></h4>
                            </a>
                        </li>
                      
                    </ul>
                </div>
        </div>

        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
	Recently, humanoid robots have made significant advances in their ability to perform challenging tasks due to the deployment of Reinforcement Learning (RL), however, the inherent complexity of humanoid robots, including the difficulty of designing complicated reward functions and training entire sophisticated systems, still poses a notable challenge.
To conquer these challenges, after many iterations and in-depth investigations, we have meticulously developed a full-size humanoid robot, "Adam", whose innovative structural design greatly improves the efficiency and effectiveness of the imitation learning process.
In addition, we have developed a novel imitation learning framework based on an adversarial motion prior, which applies not only to Adam but also to humanoid robots in general.
Using the framework, Adam can exhibit unprecedented human-like characteristics in locomotion tasks.
Our experimental results demonstrate that the proposed framework enables Adam to achieve human-comparable performance in complex locomotion tasks, marking the first time that human locomotion data has been used for imitation learning in a full-size humanoid robot.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->

     <div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Overall framework of our UniBind
            </h3>
		<p class="text-justify">
			An overview of our UniBind. Firstly, we construct the <strong>knowledge base</strong>, then learn a unified representation space via <strong>LLM-augmented contrastive learning</strong>, powered by the knowledge base. Lastly, We utilize the <strong>embedding center</strong> localized by the knowledge base to obtain the predictions.
		</p>
            <img src="./images/UniBind.png" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                The results of the emergent Zero-shot and Fine-tuning Recognition on <strong>six</strong> modalities.
            </h3>
            	<img src="./images/result.png" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                The t-SNE visualization of representation space.
            </h3>
		<img src="./images/result_space.png" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                The t-SNE visualization of embedding centers.
            </h3>
		<img src="./images/result_tsne.png" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<!-- ####      <div class="col-md-8 col-md-offset-2">
          <h3>
              Comparison on octree representations
          </h3>
          <p class="text-justify">
            DOT shows the more compact structure of DOT, 
            resulting in fewer ray intersections, explaining our significant rendering speed boost.

          </p>
		  <img src="./image/dot_cp.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>   
    <div class="col-md-8 col-md-offset-2">
        <h3>
            Comparison on visual quality and memory consumption
        </h3>
        <p class="text-justify">
            DOT provides more details in complex regions, such as sharper reflections on windows and more evident edges on fences. 

        </p>
        <img src="./image/dot_cp2.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
    </div>


		      
    	<div class="row">      
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Demo 
          </h3>   
    </div>   
      
    <div class="col-md-8 col-md-offset-2">

            <video width="800"  controls >
                <source src="./video/dot.mp4" type="video/mp4">
              Your browser does not support HTML video.
            </video>   
    </div>          
      </div>  ####-->
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@article{,
  title={UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All},
  author={Lyu,Yuanhuiyi and Zheng,Xu and Zhou,Jiazhou and Wang,Lin},
  journal={arXiv},
  year={2024}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
